{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf,desc,row_number,col,year,month,dayofmonth,hour,dayofweek,to_timestamp,size,isnan,lit,date_format,to_timestamp,struct,expr,explode,collect_list,array\n",
    "from pyspark.sql.types import MapType, StringType, IntegerType, StructType, StructField, FloatType, ArrayType, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    spark\n",
    "except NameError:\n",
    "    print('Create Spark')\n",
    "    spark=SparkSession.builder.appName(\"\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source='cuebiq'\n",
    "country='MX'\n",
    "admin_id='ageb'\n",
    "\n",
    "source='cuebiq'\n",
    "country='US'\n",
    "admin_id='census_block_group'\n",
    "\n",
    "if os.getenv('CLUSTER')=='PRINCE':\n",
    "    path_to_data='/scratch/spf248/covid/data' \n",
    "    path_to_fig='/scratch/spf248/covid/fig'    \n",
    "    %matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "else:\n",
    "    path_to_data='/user/spf248/covid/data'\n",
    "    path_to_fig='/home/spf248/covid/fig'\n",
    "    import matplotlib as mpl\n",
    "    mpl.use('Agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Aggregated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_profile=spark.read.parquet(os.path.join(path_to_data,source,'aggregates',country,'users_profile'))\n",
    "users_profile.cache()\n",
    "print('# Users:', users_profile.count()) # 21783569"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_admin=spark.read.parquet(os.path.join(path_to_data,source,'aggregates',country,'personal_admin'))\n",
    "personal_admin.cache()\n",
    "print('# Personal Areas:', personal_admin.count()) # 217190"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pings_id_personal=spark.read.parquet(os.path.join(path_to_data,source,'aggregates',country,'n_pings_id_personal'))\n",
    "n_pings_id_personal.cache()\n",
    "print('# Personal Areas:', n_pings_id_personal.count()) # 34963009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pings_id_personal_day_hour=spark.read.parquet(os.path.join(path_to_data,source,'aggregates',country,'n_pings_id_personal_day_hour'))\n",
    "n_pings_id_personal_day_hour.cache()\n",
    "total_pings=n_pings_id_personal_day_hour.select('n_pings').groupby().sum().collect()[0][0]\n",
    "print('# Pings at personal Locations:', total_pings) # 84668795782"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer Primary Home Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_admin=personal_admin.select(admin_id,'point')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_home=users_profile.select('cuebiq_id')\n",
    "\n",
    "for cutoff_day in [5,7]:\n",
    "    print()\n",
    "    print('Cutoff day:',cutoff_day)\n",
    "    for cutoff_morning in [5,7,9]:\n",
    "        print()\n",
    "        print('Cutoff morning:',cutoff_morning)\n",
    "        for cutoff_night in [19,21,23]:\n",
    "            print('Cutoff night:',cutoff_night)\n",
    "            \n",
    "            n_pings_id_personal_filtered=n_pings_id_personal_day_hour.filter(\n",
    "            n_pings_id_personal_day_hour['dayofweek']<=cutoff_day).filter(\n",
    "            (n_pings_id_personal_day_hour['hour']>=cutoff_night)|\\\n",
    "            (n_pings_id_personal_day_hour['hour']<=cutoff_morning)).groupby('cuebiq_id','point').agg(\n",
    "            {'n_pings':'sum'}).withColumnRenamed('sum(n_pings)','n_pings')\n",
    "            \n",
    "            n_pings_id_max=n_pings_id_personal_filtered.groupby('cuebiq_id').agg(\n",
    "            {'n_pings':'max'}).withColumnRenamed('max(n_pings)','n_pings')\n",
    "            \n",
    "            n_pings_id_personal_filtered_max=n_pings_id_personal_filtered.join(\n",
    "            n_pings_id_max,on=['cuebiq_id','n_pings']).drop_duplicates(\n",
    "            subset=['cuebiq_id','n_pings']).drop('n_pings')\n",
    "            \n",
    "            primary_home=primary_home.join(\n",
    "            n_pings_id_personal_filtered_max,on=['cuebiq_id']).join(personal_admin,on=['point']).withColumnRenamed(\n",
    "            'point','point_'+str(cutoff_day)+'_'+str(cutoff_morning)+'_'+str(cutoff_night)).withColumnRenamed(\n",
    "            admin_id,admin_id+'_'+str(cutoff_day)+'_'+str(cutoff_morning)+'_'+str(cutoff_night))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline = Most Frequently Allocated Block Across Specification\n",
    "mode=udf(lambda arr: Counter(arr).most_common(1)[0][0], StringType())\n",
    "primary_home=primary_home.withColumn(\n",
    "admin_id, mode(array([x for x in primary_home.columns if admin_id in x])))\n",
    "\n",
    "# Rematch with corresponding point\n",
    "primary_home=primary_home.join(personal_admin,on=admin_id)\n",
    "\n",
    "# Check unicity across specifications\n",
    "is_unique=udf(lambda arr: np.int(len(np.unique(arr))==1), IntegerType())\n",
    "primary_home=primary_home.withColumn(\n",
    "'perfect_match', is_unique(array([x for x in primary_home.columns if admin_id in x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Save Primary Home Location')\n",
    "start = timer()\n",
    "primary_home.write.mode(\"overwrite\").parquet(os.path.join(path_to_data,source,'aggregates',country,'primary_home'))\n",
    "print(\"Done in\", round(timer()-start), \"sec\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Secondary Personal Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_home=spark.read.parquet(os.path.join(path_to_data,source,'aggregates',country,'primary_home'))\n",
    "primary_home.cache()\n",
    "print('# Non-home Locations:', primary_home.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_others=n_pings_id_personal.join(primary_home,on=['cuebiq_id','point'],how='left_anti')\n",
    "personal_others.cache()\n",
    "print('# Non-home Locations:', personal_others.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_name_to_data={\n",
    "'primary_high_conf':primary_home.filter(primary_home['perfect_match']==1).select('cuebiq_id','point'),\n",
    "'primary_low_conf':primary_home.filter(primary_home['perfect_match']==0).select('cuebiq_id','point'),\n",
    "'non_primary':personal_others.select('cuebiq_id','point'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_home.groupby(admin_id).agg(\n",
    "{'cuebiq_id':'count'}).withColumnRenamed(\n",
    "'count(cuebiq_id)','n_users').repartition(1).write.mode(\"overwrite\").option('header', 'true').csv(\n",
    "os.path.join(path_to_data,source,'aggregates',country,'admin_users_pop'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hours Spent Across Personal Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Hour spent at personal location')\n",
    "start = timer()\n",
    "\n",
    "hours={}\n",
    "for personal_value in [1,2,3]:\n",
    "    print('Personal Value:', personal_value)\n",
    "    for min_days in [0,70]:\n",
    "        print('Min Days:', min_days)\n",
    "        for device_type in [0,1]:\n",
    "            print('Device:', device_type)\n",
    "            for location_name in location_name_to_data:\n",
    "                print('Location:', location_name)\n",
    "                for day_value in range(1,8):\n",
    "                    print('Day:', day_value)\n",
    "                    hours[(personal_value,min_days,device_type,location_name,day_value)]=\\\n",
    "                    n_pings_id_personal_day_hour.filter(\n",
    "                    n_pings_id_personal_day_hour['dayofweek']==day_value).join(\n",
    "                    users_profile.filter(users_profile['n_personal']==personal_value).filter(\n",
    "                    users_profile['device_type']==device_type).filter(\n",
    "                    users_profile['n_days']>min_days).select('cuebiq_id'),on='cuebiq_id').join(\n",
    "                    location_name_to_data[location_name],on=['cuebiq_id','point']).groupby('hour').agg(\n",
    "                    {'n_pings':'sum'}).withColumnRenamed('sum(n_pings)','n_pings')\n",
    "                    \n",
    "                    hours[(personal_value,min_days,device_type,location_name,day_value)].write.mode(\"overwrite\").parquet(\n",
    "                    os.path.join(path_to_data,source,'aggregates',country,'hours',str(personal_value),str(min_days),str(device_type),location_name,str(day_value)))\n",
    "                    \n",
    "print(\"Done in\", round(timer()-start), \"sec\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Hour spent at personal location')\n",
    "start = timer()\n",
    "\n",
    "hours={}\n",
    "for personal_value in [1,2,3]:\n",
    "    print('Personal Value:', personal_value)\n",
    "    for min_days in [0,70]:\n",
    "        print('Min Days:', min_days)\n",
    "        for device_type in [0,1]:\n",
    "            print('Device:', device_type)\n",
    "            for location_name in ['primary_high_conf','primary_low_conf','non_primary']:\n",
    "                print('Location:', location_name)\n",
    "                for day_value in range(1,8):\n",
    "                    print('Day:', day_value)\n",
    "                    hours[(personal_value,min_days,device_type,location_name,day_value)]=spark.read.parquet(\n",
    "                    os.path.join(path_to_data,source,'aggregates',country,'hours',str(personal_value),str(min_days),str(device_type),location_name,str(day_value))).toPandas()\n",
    "                    try:\n",
    "                        fig,ax=plt.subplots(figsize=(8,5))\n",
    "                        hours[(personal_value,min_days,device_type,location_name,day_value)].set_index('hour')['n_pings'].sort_index().plot(\n",
    "                        ax=ax,kind='bar',color='k')\n",
    "                        ax.tick_params(which='both',direction='in',pad=3)\n",
    "                        plt.xticks(rotation=0)\n",
    "                        ax.set_xlabel('Weekday hour')\n",
    "                        ax.set_ylabel('Number of pings')\n",
    "                        plt.savefig(os.path.join(path_to_fig,country,'hours-day-'+str(day_value)+'-'+str(location_name)+'-'+str(personal_value)+'-personal-location-device-'+str(device_type)+'-min-days-'+str(min_days)+'.pdf'),bbox_inches='tight')\n",
    "#                         ax.set_ylim([0,total_pings])\n",
    "                        ax.set_xlim([0,23])\n",
    "                    except:\n",
    "                        pass\n",
    "print(\"Done in\", round(timer()-start), \"sec\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Personal Locations: 34273578\n",
    "# Users with personal locations: 21417460\n",
    "# Home detected: 20992177\n",
    "# Non-home locations: 13281401\n",
    "# Non-home locations: 11624061"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
