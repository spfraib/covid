{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pygeohash as pgh\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf,desc,row_number,col,year,month,dayofmonth,hour,dayofweek,to_timestamp,size,isnan,lit,date_format,to_timestamp,struct,expr,explode,collect_list,array,length\n",
    "from pyspark.sql.types import MapType, StringType, IntegerType, StructType, StructField, FloatType, ArrayType, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    spark\n",
    "except NameError:\n",
    "    print('Create Spark')\n",
    "    spark=SparkSession.builder.appName(\"\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source='cuebiq'\n",
    "country='ID'\n",
    "geohash_precision=15 # Max precision for MX is 10 \n",
    "day_cutoffs=[5,7]\n",
    "morning_cutoffs=[7,9]\n",
    "night_cutoffs=[21,23]\n",
    "\n",
    "if os.getenv('CLUSTER')=='PRINCE':\n",
    "    path_to_data='/scratch/spf248/covid/data' \n",
    "else:\n",
    "    path_to_data='/user/spf248/covid/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_id=spark.read.parquet(os.path.join(path_to_data,source,'processed',country,'device_id'))\n",
    "device_id.cache()\n",
    "print('# Users:', device_id.count()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pings_id_personal_day_hour=spark.read.parquet(os.path.join(path_to_data,source,'processed',country,'n_pings_id_personal_day_hour'))\n",
    "n_pings_id_personal_day_hour.cache()\n",
    "total_pings=n_pings_id_personal_day_hour.select('n_pings').groupby().sum().collect()[0][0]\n",
    "print('# Pings at personal Locations:', total_pings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Primary Home Specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point2geohash=udf(lambda x,y: pgh.encode(x,y,precision=geohash_precision))\n",
    "def geohash2point(geohash):\n",
    "    (x,y)=pgh.decode(geohash)\n",
    "    return (y,x)\n",
    "schema=StructType([StructField(\"longitude\", FloatType(), False),StructField(\"latitude\", FloatType(), False)])\n",
    "geohash2point_udf=udf(geohash2point, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_home=device_id.select('cuebiq_id')\n",
    "for day_cutoff in day_cutoffs:\n",
    "    print()\n",
    "    print('Cutoff day:',day_cutoff)\n",
    "    for morning_cutoff in morning_cutoffs:\n",
    "        print('Cutoff morning:',morning_cutoff)\n",
    "        for night_cutoff in night_cutoffs:\n",
    "            print('Cutoff night:',night_cutoff)\n",
    "            # Count Pings at Night For Each Personal Area\n",
    "            n_pings_id_personal_filtered=n_pings_id_personal_day_hour.filter(\n",
    "            n_pings_id_personal_day_hour['dayofweek']<=day_cutoff).filter(\n",
    "            (n_pings_id_personal_day_hour['hour']>=night_cutoff)|\\\n",
    "            (n_pings_id_personal_day_hour['hour']<=morning_cutoff)).groupby('cuebiq_id','point').agg(\n",
    "            {'n_pings':'sum'}).withColumnRenamed('sum(n_pings)','n_pings')\n",
    "            # Find Max Ping Count\n",
    "            n_pings_id_max=n_pings_id_personal_filtered.groupby('cuebiq_id').agg(\n",
    "            {'n_pings':'max'}).withColumnRenamed('max(n_pings)','n_pings')\n",
    "            # Find Personal Area With Max Ping Count\n",
    "            n_pings_id_personal_filtered_max=n_pings_id_personal_filtered.join(\n",
    "            n_pings_id_max,on=['cuebiq_id','n_pings']).drop_duplicates(\n",
    "            subset=['cuebiq_id','n_pings']).drop('n_pings')\n",
    "            # Include As Home Candidate\n",
    "            primary_home=primary_home.join(n_pings_id_personal_filtered_max,on=['cuebiq_id'])\n",
    "            # Convert to Geohash\n",
    "            primary_home=primary_home.withColumn('geohash',point2geohash(col('point.latitude'),col('point.longitude')))\n",
    "            # Rename\n",
    "            primary_home=primary_home.withColumnRenamed(\n",
    "            'point','point_'+str(day_cutoff)+'_'+str(morning_cutoff)+'_'+str(night_cutoff)).withColumnRenamed(\n",
    "            'geohash','geohash_'+str(day_cutoff)+'_'+str(morning_cutoff)+'_'+str(night_cutoff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer Primary Home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Home = personal area with the most pings across specifications of morning/night/week\n",
    "mode=udf(lambda arr: Counter(arr).most_common(1)[0][0], StringType())\n",
    "primary_home=primary_home.withColumn(\n",
    "'geohash', mode(array([x for x in primary_home.columns if 'geohash' in x])))\n",
    "\n",
    "# Create index if home is identical across specifications\n",
    "is_unique=udf(lambda arr: np.int(len(np.unique(arr))==1), IntegerType())\n",
    "primary_home=primary_home.withColumn(\n",
    "'perfect_match', is_unique(array([x for x in primary_home.columns if 'geohash' in x])))\n",
    "\n",
    "# Map baseline home back to coordinates\n",
    "primary_home=primary_home.withColumn('point',geohash2point_udf('geohash'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Save')\n",
    "start = timer()\n",
    "primary_home.select('cuebiq_id','point','perfect_match').write.mode(\"overwrite\").parquet(\n",
    "os.path.join(path_to_data,source,'processed',country,'primary_home'))\n",
    "print(\"Done in\", round(timer()-start), \"sec\")        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
