{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "results_path = \"/results/\"\nstart_date='2020-01-01'\nend_date='2020-04-16'\nsource='cuebiq'\ncountry='ID'\nadmin_id='ADM4_PCODE'\nstart_hour_day = 8\nend_hour_day = 20"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compute entropy of neighborhood visits"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "pings_geocoded = spark.read.parquet(os.path.join(results_path,source, 'processed',country,'pings_geocoded'))\n"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "pings_geocoded = pings_geocoded.where((pings_geocoded.time >= start_date) & (pings_geocoded.time <= end_date))\npings_geocoded = pings_geocoded.withColumn(\"date\", F.date_format('time','yyyy-MM-dd'))"
   ],
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "w = Window.partitionBy(\"cuebiq_id\")\ntmp = pings_geocoded.groupBy(\"date\", \"cuebiq_id\").agg(F.count(admin_id).alias(\"ind_count\")).withColumn(\"tot_count\", F.sum(\"ind_count\").over(w))\ntmp = tmp.withColumn(\"p\", F.col(\"ind_count\")/F.col(\"tot_count\"))\nentropy_date_id=tmp.groupby(\"date\", \"cuebiq_id\").agg((-F.sum(F.col(\"p\") * F.log2(F.col(\"p\")))).alias(\"entropy\"))\nentropy_date_id = entropy_date_id.join(tmp.select(\"date\", \"cuebiq_id\", F.col(\"tot_count\").alias(\"n_pings\")), on = [\"date\", \"cuebiq_id\"])\n\n\ntmp = pings_geocoded.filter((F.hour(F.col(\"time\")) >= 8) & (F.hour(F.col(\"time\")) <= 20)).groupBy(\"date\", \"cuebiq_id\").agg(F.count(admin_id).alias(\"ind_count\")).withColumn(\"tot_count\", F.sum(\"ind_count\").over(w))\ntmp = tmp.withColumn(\"p\", F.col(\"ind_count\")/F.col(\"tot_count\"))\nentropy_daytime_id= tmp.groupby(\"date\", \"cuebiq_id\").agg((-F.sum(F.col(\"p\") * F.log2(F.col(\"p\")))).alias(\"entropy\"))\nentropy_daytime_id = entropy_daytime_id.join(tmp.select(\"date\", \"cuebiq_id\", F.col(\"tot_count\").alias(\"n_pings\")), on = [\"date\", \"cuebiq_id\"])\n\ntmp = pings_geocoded.filter(((F.hour(F.col(\"time\")) >= 20) & (F.hour(F.col(\"time\")) <= 23)) |((F.hour(F.col(\"time\")) >= 0) & (F.hour(F.col(\"time\")) <= 8))).groupBy(\"date\", \"cuebiq_id\").agg(F.count(admin_id).alias(\"ind_count\")).withColumn(\"tot_count\", F.sum(\"ind_count\").over(w))\ntmp = tmp.withColumn(\"p\", F.col(\"ind_count\")/F.col(\"tot_count\"))\nentropy_nighttime_id= tmp.groupby(\"date\", \"cuebiq_id\").agg((-F.sum(F.col(\"p\") * F.log2(F.col(\"p\")))).alias(\"entropy\"))\nentropy_nighttime_id = entropy_nighttime_id.join(tmp.select(\"date\", \"cuebiq_id\", F.col(\"tot_count\").alias(\"n_pings\")), on = [\"date\", \"cuebiq_id\"])\n "
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "results_path = '/dbfs/results/'"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "\nentropy_date_id.toPandas().to_csv(os.path.join(results_path,source,'processed',country,'entropy_date_id.csv'), index=False)\nentropy_daytime_id.toPandas().to_csv(os.path.join(results_path,source,'processed',country,'entropy_daytime_id.csv'), index = False)\nentropy_nighttime_id.toPandas().to_csv(os.path.join(results_path,source,'processed',country,'entropy_nighttime_id.csv'), index = False)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Figures"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "mimetype": "text/x-python",
   "name": "python",
   "pygments_lexer": "ipython3",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "name": "describe-users-entropy-of-visits-spark",
  "notebookId": 351841791785760
 },
 "nbformat": 4,
 "nbformat_minor": 0
}