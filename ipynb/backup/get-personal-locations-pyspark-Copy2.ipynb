{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spark-submit --master yarn --deploy-mode cluster  --conf spark.yarn.submit.waitAppCompletion=false --conf spark.serializer=org.apache.spark.serializer.KryoSerializer --conf spark.speculation=false --conf spark.executorEnv.LANG=en_US.UTF-8 --conf spark.yarn.appMasterEnv.LANG=en_US.UTF-8 --driver-cores 20 --driver-memory 20G --num-executors 40 --executor-cores 15 --executor-memory 25G ./covid/py/get-personal-locations-pyspark.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Time: 3941.828 sec\n"
     ]
    }
   ],
   "source": [
    "print('Computing Time:',(1585581654521-1585577712693)/1000,'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf,desc,row_number,col,year,month,dayofmonth,hour,dayofweek,to_timestamp,size,isnan,lit,date_format,to_timestamp,struct,expr,array,max\n",
    "from pyspark.sql.types import MapType, StringType, IntegerType, StructType, StructField, FloatType, ArrayType, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    spark\n",
    "except NameError:\n",
    "    spark=SparkSession.builder.appName(\"\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source='cuebiq'\n",
    "country='US'\n",
    "\n",
    "if os.getenv('CLUSTER')=='PRINCE':\n",
    "    path_to_data='/scratch/spf248/covid/data'\n",
    "    directories=['*'+str(x)+'00' for x in range(10)][1:2]\n",
    "    file='part-00000-0428e20d-9019-4cbf-b5ce-bc9414007fec-c000.csv.gz'\n",
    "else:\n",
    "    path_to_data='/user/spf248/covid/data'\n",
    "    directories=['*'+str(x)+'00' for x in range(10)]\n",
    "    file='*'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema= StructType([\n",
    "StructField(\"_c0\", FloatType(), False),\n",
    "StructField(\"_c1\", StringType(), False),\n",
    "StructField(\"_c2\", FloatType(), False),\n",
    "StructField(\"_c3\", FloatType(), False),\n",
    "StructField(\"_c4\", FloatType(), False),\n",
    "StructField(\"_c5\", FloatType(), False),\n",
    "StructField(\"_c6\", FloatType(), False),\n",
    "StructField(\"_c7\", StringType(), False),\n",
    "StructField(\"_c8\", StringType(), False),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(directory):\n",
    "    \n",
    "    df=spark.read.option(\n",
    "    'compression', 'gzip').option(\n",
    "    'header', 'false').option(\n",
    "    \"multiLine\", \"true\").option(\n",
    "    'escape','\"').option(\n",
    "    \"encoding\", \"UTF-8\").option(\n",
    "    \"delimiter\", \"\\t\").schema(schema).csv(\n",
    "    os.path.join(\n",
    "    path_to_data,\n",
    "    source,\n",
    "    country,\n",
    "    directory,\n",
    "    file))\n",
    "    \n",
    "    df.cache()\n",
    "\n",
    "    column_names=[\n",
    "    'timestamp',\n",
    "    'cuebiq_id',\n",
    "    'device_type',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'accuracy',\n",
    "    'time_zone_offset',\n",
    "    'classification_type',\n",
    "    'transformation_type']\n",
    "    df=df.toDF(*column_names)\n",
    "\n",
    "    df=df.withColumn(\"time\",to_timestamp(df[\"timestamp\"]+df[\"time_zone_offset\"]))\n",
    "    df=df.filter(df['classification_type']=='PERSONAL_AREA')\n",
    "    df=df.withColumn('hour',hour(\"time\"))\n",
    "    df=df.withColumn('dayofweek',dayofweek(\"time\"))\n",
    "    df=df.withColumn('point',struct('longitude','latitude'))\n",
    "\n",
    "    return df.groupby('cuebiq_id','point','dayofweek','hour').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,directory in enumerate(directories):\n",
    "    if not i:\n",
    "        users=get_summary(directory)\n",
    "        users.cache()\n",
    "    else:\n",
    "        users=users.unionByName(get_summary(directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Save Personal Locations')\n",
    "users=users.groupby('cuebiq_id','point','dayofweek','hour').agg(\n",
    "{'count':'sum'}).withColumnRenamed('sum(count)','count')\n",
    "users.write.mode(\"overwrite\").parquet(os.path.join(path_to_data,source,country,'personal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+----+-----+\n",
      "|           cuebiq_id|               point|dayofweek|hour|count|\n",
      "+--------------------+--------------------+---------+----+-----+\n",
      "|21a253b012efda42d...|[-118.25058, 34.0...|        3|  17|    1|\n",
      "|4c035b57f75f041ac...|[-89.65056, 41.81...|        4|   0|    5|\n",
      "|4ceb457337b65dcc5...|[-88.087524, 39.9...|        4|   3|    2|\n",
      "|9883f2f68789cdfdb...|[-85.49249, 38.23...|        3|  19|    5|\n",
      "|45ed687a83fe33bc6...|[-75.67466, 41.42...|        3|  16|    6|\n",
      "|2214401b40bb7dca0...|[-70.96851, 42.54...|        4|  12|    1|\n",
      "|bd705702d90e59802...|[-82.642876, 27.8...|        3|   8|    1|\n",
      "|640419b48a5c3bb74...|[-105.24425, 35.6...|        4|   1|    1|\n",
      "|a98e8849986e03c23...|[-80.212105, 26.0...|        3|  17|    3|\n",
      "|480279bd3fa0f8b8f...|[-85.00785, 41.20...|        4|  13|    2|\n",
      "|480279bd3fa0f8b8f...|[-85.00785, 41.20...|        4|  10|    1|\n",
      "|08208a616a43c6c63...|[-91.59524, 41.70...|        4|   4|    1|\n",
      "|e9839857f51ab6cdf...|[-71.216125, 42.8...|        4|   4|    5|\n",
      "|2a5b5c27952f35d43...|[-76.7751, 37.07287]|        3|  13|   10|\n",
      "|0aa0c05f3f160760f...|[-80.71331, 34.99...|        4|   0|    1|\n",
      "|68f5a0ffd3238796f...|[-82.23125, 37.62...|        4|   5|    5|\n",
      "|618928b11d4bcf664...|[-77.88757, 42.72...|        4|   5|    1|\n",
      "|57f86722a10f6f8e1...|[-117.61835, 33.6...|        4|   1|    5|\n",
      "|ce2f15c406a5ec75e...|[-95.58051, 30.13...|        4|   4|    6|\n",
      "|a1775f9654aca92d4...|[-110.90149, 32.2...|        3|  22|    4|\n",
      "+--------------------+--------------------+---------+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
