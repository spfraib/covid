{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf,desc,row_number,col,year,month,dayofmonth,hour,dayofweek,to_timestamp,size,isnan,lit,date_format,to_timestamp,struct,expr,explode\n",
    "from pyspark.sql.types import MapType, StringType, IntegerType, StructType, StructField, FloatType, ArrayType, DoubleType\n",
    "\n",
    "from geospark.register import GeoSparkRegistrator\n",
    "from geospark.utils import GeoSparkKryoRegistrator, KryoSerializer\n",
    "from geospark.register import upload_jars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_jars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Spark\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    spark\n",
    "except NameError:\n",
    "    print('Create Spark')\n",
    "    spark=SparkSession.builder.appName(\"\").config(\n",
    "    \"spark.serializer\", KryoSerializer.getName).config(\n",
    "    \"spark.kryo.registrator\", GeoSparkKryoRegistrator.getName).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GeoSparkRegistrator.registerAll(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "source='cuebiq'\n",
    "country='ID'\n",
    "\n",
    "if os.getenv('CLUSTER')=='PRINCE':\n",
    "    path_to_data='/scratch/spf248/covid/data'\n",
    "else:\n",
    "    path_to_data='/user/spf248/covid/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal=spark.read.parquet(os.path.join(path_to_data,source,'aggregates',country,'n_pings_id_personal'))\n",
    "personal=personal.select('point').drop_duplicates(subset=['point'])\n",
    "personal.createOrReplaceTempView(\"personal\")\n",
    "\n",
    "personal=spark.sql(\"\"\"select point.latitude as latitude\n",
    ", point.longitude as longitude\n",
    ", ST_Point(cast(personal.point.longitude as Decimal(24,20))\n",
    ", cast(personal.point.latitude as Decimal(24,20))) as point\n",
    "from personal\n",
    "\"\"\")\n",
    "personal.createOrReplaceTempView(\"personal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('# Personal Locations:', personal.count()) # US: 218137 / MX: 46545 / ID: 26379"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin=spark.read.option(\n",
    "\"header\", \"true\").csv(\n",
    "os.path.join(\n",
    "path_to_data,\n",
    "'admin',\n",
    "country,\n",
    "'admin.csv'))\n",
    "admin.createOrReplaceTempView(\"admin\")\n",
    "\n",
    "query=\"select\"\n",
    "for column in admin.columns:\n",
    "    if column == 'geometry' or column=='polygon':\n",
    "        continue\n",
    "    query+=\" admin.\"+column+\" as \"+column+\",\"\n",
    "query+=\" ST_GeomFromText(admin.geometry) as polygon from admin\"\n",
    "\n",
    "admin=spark.sql(query)\n",
    "admin.createOrReplaceTempView(\"admin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('# Admin Units:', admin.count()) # US: 220320/ MX: 56177 / ID: 72300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"SELECT p.latitude, p.longitude\"\n",
    "for column in admin.columns:\n",
    "    if column == 'geometry' or column=='polygon':\n",
    "        continue\n",
    "    query+=\", s.\"+column\n",
    "query+=\" FROM personal as p, admin as s WHERE ST_Intersects(p.point, s.polygon)\"\n",
    "\n",
    "personal_admin=spark.sql(query)\n",
    "personal_admin=personal_admin.withColumn('point',struct('longitude','latitude')).drop('longitude','latitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('# Matched Locations:', personal_admin.count()) # US: 217190 / MX: 24512 / ID: 24711"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Geocoded Locations\n",
      "Done in 98 sec\n"
     ]
    }
   ],
   "source": [
    "print('Save Geocoded Locations')\n",
    "start = timer()\n",
    "\n",
    "personal_admin.write.mode(\"overwrite\").parquet(os.path.join(path_to_data,source,'aggregates',country,'personal_admin'))\n",
    "\n",
    "print(\"Done in\", round(timer()-start), \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+----------+---------------+----------+-------+----------+----------+------------------+----------------+--------------------+\n",
      "|  ADM4_PCODE|           ADM3_EN|ADM3_PCODE|        ADM2_EN|ADM2_PCODE|ADM1_EN|ADM1_PCODE|median_age|      wealth_index|total_population|               point|\n",
      "+------------+------------------+----------+---------------+----------+-------+----------+----------+------------------+----------------+--------------------+\n",
      "|ID1172010007|          Sukajaya| ID1172010|    Kota Sabang|    ID1172|   Aceh|      ID11|      26.0|0.7582239837506708|          5510.0|[95.33386, 5.8859...|\n",
      "|ID1172010010|          Sukajaya| ID1172010|    Kota Sabang|    ID1172|   Aceh|      ID11|      25.0|0.7305132011677065|          3652.0|[95.33386, 5.8914...|\n",
      "|ID1172020007|         Sukakarya| ID1172020|    Kota Sabang|    ID1172|   Aceh|      ID11|      27.0|0.7187204600457259|          3069.0|[95.31189, 5.8914...|\n",
      "|ID1172010007|          Sukajaya| ID1172010|    Kota Sabang|    ID1172|   Aceh|      ID11|      26.0|0.7582239837506708|          5510.0|[95.33386, 5.880432]|\n",
      "|ID1172020008|         Sukakarya| ID1172020|    Kota Sabang|    ID1172|   Aceh|      ID11|      28.0|0.7787383210862042|          3764.0|[95.322876, 5.896...|\n",
      "|ID1172020001|         Sukakarya| ID1172020|    Kota Sabang|    ID1172|   Aceh|      ID11|      25.0|0.5650116185178825|           842.0|[95.267944, 5.852...|\n",
      "|ID1172020002|         Sukakarya| ID1172020|    Kota Sabang|    ID1172|   Aceh|      ID11|      27.0|0.5236322343099865|           974.0| [95.3009, 5.836487]|\n",
      "|ID1172020006|         Sukakarya| ID1172020|    Kota Sabang|    ID1172|   Aceh|      ID11|      27.0|0.6893379598953208|          2127.0|[95.322876, 5.891...|\n",
      "|ID1108090028|        Ingin Jaya| ID1108090|     Aceh Besar|    ID1108|   Aceh|      ID11|      22.5|0.6212808719422072|           602.0|[95.34485, 5.5178...|\n",
      "|ID1171011005|         Jaya Baru| ID1171011|Kota Banda Aceh|    ID1171|   Aceh|      ID11|      24.0|0.7736237394582959|          2441.0|[95.3009, 5.5233765]|\n",
      "|ID1171040013|       Syiah Kuala| ID1171040|Kota Banda Aceh|    ID1171|   Aceh|      ID11|      21.0|0.7160720575500894|          5207.0|[95.36682, 5.567322]|\n",
      "|ID1108070022|         Kuta Baro| ID1108070|     Aceh Besar|    ID1108|   Aceh|      ID11|      21.0|0.5936708211590382|           701.0|[95.388794, 5.534...|\n",
      "|ID1108110026|      Darul Imarah| ID1108110|     Aceh Besar|    ID1108|   Aceh|      ID11|      25.0|0.7696808262501575|          4736.0|[95.3009, 5.5178833]|\n",
      "|ID1171010025|           Meuraxa| ID1171010|Kota Banda Aceh|    ID1171|   Aceh|      ID11|      25.0|0.7784184230191848|          3272.0|[95.31189, 5.5508...|\n",
      "|ID1108060023|        Darussalam| ID1108060|     Aceh Besar|    ID1108|   Aceh|      ID11|      25.0|0.6142217270494503|           635.0|[95.39978, 5.5892...|\n",
      "|ID1171020009|      Baiturrahman| ID1171020|Kota Banda Aceh|    ID1171|   Aceh|      ID11|      26.0|0.7391804432510739|          1472.0|[95.322876, 5.539...|\n",
      "|ID1171021005|        Lueng Bata| ID1171021|Kota Banda Aceh|    ID1171|   Aceh|      ID11|      24.0|0.7278617871234645|          1994.0|[95.33386, 5.545349]|\n",
      "|ID1171020014|      Baiturrahman| ID1171020|Kota Banda Aceh|    ID1171|   Aceh|      ID11|      25.0|0.7563797399909287|          5642.0|[95.322876, 5.550...|\n",
      "|ID1108110042|      Darul Imarah| ID1108110|     Aceh Besar|    ID1108|   Aceh|      ID11|      23.0|0.7456497384896015|          2201.0|[95.322876, 5.517...|\n",
      "|ID1108091006|Krueng Barona Jaya| ID1108091|     Aceh Besar|    ID1108|   Aceh|      ID11|      24.0|0.7352589295875785|          1012.0|[95.36682, 5.545349]|\n",
      "+------------+------------------+----------+---------------+----------+-------+----------+----------+------------------+----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "personal_admin.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
